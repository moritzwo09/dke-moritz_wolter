Benjamin F. Trueman,* Madison Gouthro, Amina K. Stoddart, and Graham A. Gagnon 3! Centre for Water Resources Studies, Department of Civil & Resource Engineering, 4!
Dalhousie University, 1360 Barrington St., Halifax, Nova Scotia, Canada B3H 4R2 5!
*Corresponding author 7!
E-mail: benjamin.trueman@dal.ca 8!
Tel: 902.494.6070 9!
Fax: 902.494.3105 10!
Non-detects—measurements reported as “below the detection limit”—are ubiquitous in 12! environmental science and engineering. They are frequently replaced with a constant, 13! but this biases estimates of means, regression slopes, and correlation coefficients. 14! Omitting non-detects is worse, and has led to serious errors. Simple alternatives are 15! available: rank-based statistics, maximum likelihood estimation, and re-purposed 16! survival analysis routines. But many environmental datasets do not align well with the 17! assumptions these methods make—it is often necessary to account for hierarchy (e.g., 18! measurements nested within lakes), sampling strategy (e.g., measurements collected 19! as time series), heterogeneity (e.g., site-dependent variance), and measurement error. 20! Bayesian methods offer the flexibility to do this; incorporating non-detects is also easy 21! and does not bias model parameter estimates as substitution does. Here we discuss 22! Bayesian implementations of common bivariate and multivariate statistical methods 23! relevant to environmental science. We use a dataset comprising time series of Ag, As, 24! Cd, Ce, Co, Sb, Ti, U, and V concentrations in municipal biosolids that includes many 25! non-detects. The models can be reproduced and extended to new problems using the 26! data and code accompanying this paper. 27!
Non-detects—measurements recorded as less than a detection or reporting limit—are 31! ubiquitous in environmental science and engineering. In the statistical literature, they 32! are known as left-censored observations. A popular method of representing them in 33! statistical routines is to replace them with one-half, or some other fraction, of the 34! detection limit. But while common, this strategy can severely bias estimates based on 35! the data when the censoring rate is high. Worse still is omission—leaving out non-36! detects has led to serious and well-documented errors. 37!
For basic tasks like comparing two groups or estimating a mean, linear regression 38! slope, or correlation coefficient, there are simple alternatives to substitution and 39! omission. These include rank-based methods, maximum likelihood estimation, and re-40! purposed survival analysis routines. But many environmental datasets require more 41! complex models that account for hierarchy, sampling strategy, heterogeneity, and 42! measurement error. For instance, measurements may be collected across multiple 43! lakes with different characteristics or they may be recorded as time series (i.e., serially 44! dependent data). The standard toolbox for censored data analysis does not always 45! accommodate these features. 46!
Bayesian methods excel in this context—since the sampling techniques they rely on 47! provide a near-universal approach to parameter estimation, they can be very flexible. In 48! particular, it is straightforward to account for non-detects in almost any model. Here, we 49! provide examples of common statistical models in environmental science and 50! engineering whose Bayesian versions can easily accommodate non-detects. They are 51! reproducible via the code and data that accompany this paper. 52!
We fit models to a dataset comprising concentrations of Ag, As, Cd, Ce, Co, Sb, Ti, U, 55! and V in municipal biosolids. Biosolids samples were collected from the clarifiers of 56! three wastewater treatment facilities in 125 mL polypropylene bottles. Samples were 57! autoclaved, desiccated by baking at 105°C for approximately 60 hours, digested 58! according to EPA Method 3050B, diluted serially, and quantified by inductively coupled 59! plasma mass spectrometry according to Standard Method 3125. data is available in Table 1. 61!
Table 1. A summary of element concentrations in biosolids samples collected at three 62! wastewater treatment facilities. 63!
The data and code necessary to reproduce the main results from this paper are 65! available at https://github.com/bentrueman/censored-env-data-analysis; several 66! functions used to fit the models in Stan are available in a separate R package. used R version 4.3.3 throughout, along with a collection of contributed packages.
 A summary of the 60!
Bayesian inference entails fitting a probability model to data, then summarizing it as the 71! joint distribution of the model parameters, 𝜃. The model starts as a prior, 𝑃 quantifying the plausibility of all possible parameter values. The prior reflects 73! background knowledge and practical considerations. 74!
The data, 𝑥, are used to update the prior via Bayes’ theorem. It relates the posterior or 75! updated joint parameter distribution, 𝑃(𝜃|𝑥), with the prior and the likelihood. The 76! likelihood, 𝑃(𝑥|𝜃), quantifies the compatibility of the data with the proposed model. 77!
In practice, model fitting follows these basic steps: 78!
Iterating over steps 4 (a–d) may require searching a high-dimensional parameter space, 89! which is often accomplished via the Hamiltonian Monte Carlo algorithm. software packages make this straightforward: the R package brms huge variety of Bayesian regression models—including censored data models—with a 92! standard and familiar syntax. Further customization is possible using Stan, programming platform for Bayesian statistics written in C++. 94!
Replacing non-detects with a constant can bias parameter estimates substantially, 96! especially when the censoring rate is high. We show this using a small simulation study 97! that compares substitution at one-half the detection limit with a parameter estimation 98! strategy that relies on the cumulative distribution function. 99!
, for instance, fits a 91!
When the dependent variable in a linear regression model includes left-censored 100! observations, one method of accounting for them is to construct the likelihood for every 101! censored observation using the appropriate cumulative distribution function in place of 102! the probability density function. Here, the cumulative distribution function quantifies the 103! probability that a data point is less than the detection limit—that is, the compatibility of a 104! non-detect with the proposed model. The likelihood, then, becomes 𝑃 𝐹(𝑥|𝜃)𝐺(𝑥|𝜃), where 𝐹 and 𝐺 are the probability density and cumulative 106! distribution functions, respectively. 107!
We simulated from a simple linear regression model, 𝑦∼𝑁( where the dependent variable was partially censored—here, 𝑁 represents the normal 109! distribution with mean 𝜇 and standard deviation 𝜎. We fit a censored regression using 110! brms where the simulated non-detects were modeled using the normal cumulative 111! distribution function. We compared it to a naive model where the non-detects were 112! replaced with one-half the detection limit. 113!
Specifically, the 𝑖 simulated observations, 𝑦, were modeled as follows. Except for the 114! special handling of left-censored observations (𝑦|𝑐𝑒𝑛𝑠𝑜𝑟𝑒 𝑑 identical. 116!
In equation (1), 𝑐𝑒𝑛𝑠𝑜𝑟𝑒 𝑑 is a binary variable (0=𝑜𝑏𝑠𝑒𝑟𝑣𝑒𝑑, 1=𝑙𝑒𝑓𝑡-𝑐𝑒𝑛𝑠𝑜𝑟𝑒𝑑), and 118! 𝑁-𝐶𝐷𝐹 is the normal cumulative distribution function (i.e., 𝑃(𝑋≤𝑥 a random variable 𝑋 is less than or equal to some value 𝑥). 𝜇=3+0.15𝑥,𝜎=0.5), 108!
=1), the naive model was 115! likelihood: 𝑜𝑏𝑠𝑒𝑟𝑣𝑒𝑑] priors:
), the probability that 119! The parameters 𝛽 and 120! 𝛽 define the linear model for 𝜇, and 𝑇 denotes the t distribution with degrees of 121! freedom—which controls probability density in the tails—parameterized by 𝜈. 122!
Figure 1. (a) One iteration of the linear regression simulation. The model that accounts 124! for left-censoring via the cumulative distribution function recovered the true model 125! parameters well, whereas the naive model that used substitution at one-half the 126! detection limit was biased. Points represent observations, and vertical dashed grey lines 127! represent left-censored values. (b) The same pattern was evident across the entire 128! simulation: the censored regression model recovered the true parameters well and the 129! naive model was biased. 130! The censored regression model recovered the true parameter values much more 131! accurately than the naive model (Figure 1). That is, the censored model yielded 95% 132! credible intervals on the intercept, slope, and residual standard deviation that included 133! the true parameter values 96, 98, and 97% of the time, respectively. The naive model 134! yielded intervals that included the true values just 2, 14, and 1% of the time. 135!
The same strategy can be incorporated into more complex models: here, we use a 137! dataset of metals concentrations in municipal biosolids to demonstrate fitting a 138! smoothing spline, a popular method for characterizing environmental time series and 139! other problems. It was fitted using bgamcar1, an extension of brms that 140! accommodates continuous-time autoregression—accounting for the dependence of one 141! observation on the previous one in unequally spaced time series. concentrations at three wastewater treatment facilities (Sites 1–3) were modeled as 143! follows: 144! where, in addition to the symbols defined above, 𝐻𝑎𝑙𝑓-𝑇 represents the positive-valued t 146! distribution and 𝐺𝑎𝑚𝑚𝑎 the gamma distribution, parameterized by mean 𝜇 and shape 147! parameter 𝛼. The linear model 𝛽𝑋 estimates a separate intercept for each site, 148! where 𝑋 is the design matrix and 𝛽 the coefficients. The autocorrelation 149! coefficient, 𝜙, and the residual at time 𝑡−𝑠, 𝑟, define the dependence of each 150! observation on the previous one, where 𝑠 is the spacing between adjacent 151! observations. 152!
The term 𝑓(𝑡) is a smooth spline function that captures nonlinear variation in the mean 153! with time. It takes the following form: 154! likelihood: 𝑙𝑒𝑓𝑡-𝑐𝑒𝑛𝑠𝑜𝑟𝑒𝑑] model for 𝜇:
=2.5,𝜈=3) =2.5,𝜈=3M =2,𝛼=0.1)
=2.5,𝜈=3) where 𝑍 and 𝑋 are matrices representing the penalized and unpenalized basis 156! functions, while 𝛽 and 𝑏 represent the corresponding spline coefficient vectors.
Figure 2. Titanium concentration time series representing biosolids collected at three 159! locations (light lines). Model predictions are superimposed in bold, the shaded regions 160! represent a 95% credible interval on the posterior mean, and non-detects are shown as 161! vertical dashed lines extending to the detection limit. A single value beyond the plot 162! limits is annotated. 163!
Geometric mean titanium concentrations varied in a quasi-seasonal pattern (Figure 2), 164! and samples collected at one facility, Site 3, had mean concentrations approximately 165!
20–30 µg g higher than those representing the other two facilities. Observations 166! exhibited mild serial correlation, which quantifies the dependence of each observation 167!
+𝑍𝑏 𝑝𝑒𝑛𝑎𝑙𝑖𝑧𝑒𝑑] on the previous one, after accounting for trends and site-specific variation. The serial 168! correlation parameter in the model, 𝜙, had a posterior median of 0.11 with a 95% 169! credible interval spanning 0.03–0.26. In general, accounting for serial correlation 170! improves the accuracy of predictions and helps avoid overfitting.
Left-censoring may also occur in the predictor variable. One potential application is 173! building a linear regression model to predict missing values in one variable using 174! another, partially censored, variable. Left-censored predictors, though, are not 175! amenable to substituting a cumulative distribution function in the likelihood—another 176! strategy is required. 177!
Figure 3. Cobalt concentrations as a function of cadmium concentrations in biosolids 179! from three treatment facilities. Nondetect cadmium concentrations are represented as 180! horizontal lines extending to the detection limit. A robust (Student t) linear model is 181! superimposed in blue and the shaded region represents a 95% credible interval on the 182! posterior mean. The equivalent non-robust model yields an extremely wide credible 183! interval due to the unusually high cobalt concentration of 309 µg g outside the plotting limits are annotated in parentheses. 185! Fortunately, there is a straightforward alternative: all the non-detects can be treated as 186! missing values with an upper bound and represented by parameters in the model. Since 187! Bayesian modeling results in a set of posterior draws—vectors of plausible parameter 188!
. Coordinates 184! values—this is similar to multiple imputation of missing values with an upper—and 189! optionally a lower—bound. But since it is done in one step, we get a joint distribution 190! that quantifies the uncertainty and interrelationships among all the parameters, including 191! the censored values. This might be important, for instance, when there is serial 192! dependence in the data. 193!
Another advantage is the size of the imputed dataset: since the model is fitted to the 194! data just once, it is straightforward to generate several thousand imputed values, even 195! for complex models. This may not be practical if values are imputed before model fitting: 196! the conventional imputation strategy entails fitting one model for each set of imputed 197! values. Furthermore, it may be difficult to find a multiple imputation routine that meets all 198! of the needs of a particular data analysis. 199!
Using the Bayesian approach, we can specify any predictive model we would like to 200! impute the censored values. Since there were only a few censored observations in this 201! pair of variables (Figure 3), we chose a simple intercept-only imputation model, fitted 202! using bgamcar1. It was defined as follows: 203!
When the model was fitted with a Gaussian likelihood, the extreme cobalt concentration 205! of 309 µg g yielded a posterior mean with an extremely wide credible interval (Figure 206! 3). The robust model, fitted with a Student t likelihood, yielded a much narrower credible 207!
 204! priors: interval and a posterior mean that was much less heavily influenced by the extreme 208! value. A disadvantage of both models is that simulating from them may generate 209! negative concentrations, even though the posterior mean remains positive over its 210! range. This could be solved by modeling log-transformed Co concentrations instead, 211! resulting in a slightly different interpretation: the model would then predict geometric 212! mean concentrations on the scale of measurement. 213!
In a multivariate context, the one-step multiple imputation strategy is often simpler to 215! apply, since multivariate cumulative distribution functions can be difficult to implement. 216! Two multivariate models with applications in environmental science are the intercept-217! only model, used to estimate a correlation matrix, and principal component analysis. 218!
A Bayesian correlation matrix 219! In addition to handling non-detects, Bayesian correlation has the advantage that it can 220! be readily applied to variables that are best described using distributions other than the 221! Gaussian. A relevant example for environmental sciences is robust correlation, where a 222! Student t distribution is assigned to each variable and its parameters estimated. This 223! tends to limit the influence of extreme values, which might otherwise exert undue 224! influence on the estimated correlation coefficients. 225!
Given 𝑦, an 𝑁×𝐷 matrix containing 𝑁 concentrations of 𝐷 elements, we can estimate 226! the pairwise correlations as follows: 227! where the 𝜇 are the column means of 𝑦, 𝛴 is the covariance matrix, the 𝜎 column standard deviations of 𝑦, and 𝑅 is the correlation matrix. 𝐿𝐾𝐽𝑐𝑜𝑟𝑟 regularizing prior that encodes mild skepticism of extreme correlation coefficients near -231! 1 or 1. 232! priors:
Figure 4. (a) Pairwise Bayesian correlations among the elemental concentrations in the 234! dataset, estimated using Student t and Gaussian likelihoods. (b) The robust model—235! fitted with Student t likelihoods—identifies more correlation than the non-robust model 236! fitted with Gaussian likelihoods. 237! Arsenic, vanadium, and cadmium concentrations were most strongly correlated in 238! biosolids (Figure 4). And overall, the robust model—incorporating Student t 239! likelihoods—identified more correlation among the variables than the conventional, non-240! robust model fitted with Gaussian likelihoods. This is due to the much smaller influence 241! that extreme values have on the robust model. 242!
Probabilistic principal components analysis 243! Principal component analysis is a method for summarizing a multivariate dataset using 244! a subset of derived variables that capture the majority of the data’s variance. implement probabilistic principal component analysis, a Bayesian generalization of the 246! classical approach. Our model is modified from the approach described in a recent 247! paper to accommodate left-censoring of the data and is written in Stan 𝐷×𝑁 matrix containing 𝑁 concentrations of 𝐷 elements, 249! where 𝑧 is a 𝑘×𝑁 matrix of latent (i.e., unobserved) variables with 𝑘≤𝐷, 𝑊 is a 𝐷×𝑘 251! transformation matrix mapping from the latent space to the data space, 𝜎 is the 252! standard deviation of the error (also a latent parameter), 𝐼 is the identity matrix, and 253! 𝐼𝑛𝑣𝐺𝑎𝑚𝑚𝑎 is the inverse gamma distribution. 254!
0,𝐼) 250!
Figure 5. (a) The dataset projected onto the first two probabilistic principal components 256!
(z in equation (6)). Values appearing outside the extents of the plot are annotated in 257! parentheses at the margins. (b) The first two principal axes; that is, the orthonormalized 258! columns of the transformation matrix 𝑊. 259! Differences in metals concentrations among the three sites are apparent in Figure 5a. In 260! particular, Site 3 scored differently on the two principal components, resulting in 261! substantial separation in the two-component space from the data representing the other 262! two sites. Differences in titanium concentrations among treatment facilities play a strong 263! role here: the principal axes—that is, the orthonormalized columns of the transformation 264! matrix 𝑊 (equation 6)—load titanium concentrations heavily. And titanium 265! concentrations were high in biosolids from Site 3 relative to Sites 1 and 2 (Figure 2). 266!
Replacing non-detects with a constant—often one-half the detection limit—biases 268! estimates of means, regression slopes, and correlation coefficients. Simple alternatives 269! exist, but they are limited and not always applicable to complex environmental datasets 270! that exhibit hierarchy, complex dependence structures, and heterogeneity. Bayesian 271! methods have the flexibility to model all of these features, and they can easily 272! accommodate left-censoring by either modifying the likelihood or one-step multiple 273! imputation as a part of model fitting. 274!
This work was supported by NSERC through an Alliance Grant (ALLRP 568507–21). 276! We acknowledge utility staff for facilitating sample collection at the treatment facilities 277! and Heather Daurie, Alyssa Chiasson, Evelyne Doré, Jorginea Bonang, Genevieve 278! Erjavec, Sebastian Munoz, and Bofu Li for laboratory assistance. 279!
2nd ed.; Wiley series in statistics in practice; Wiley: Hoboken, N.J, 2012. 282!
Sediments, Sludges, and Soils. Test methods for evaluating solid waste, 284! physical/chemical methods 1996. 285!
Plasma—Mass Spectrometry. In Standard methods for the examination of water and 287! wastewater; 2018. https://doi.org/10.2105/SMWW.2882.048. 288! https://github.com/bentrueman/bgamcar1. 290! https://www.R-project.org/. 292!
Grolemund, G.; Hayes, A.; Henry, L.; Hester, J.; Kuhn, M.; Pedersen, T. L.; Miller, E.; 294!
Bache, S. M.; Müller, K.; Ooms, J.; Robinson, D.; Seidel, D. P.; Spinu, V.; Takahashi, 295!
K.; Vaughan, D.; Wilke, C.; Woo, K.; Yutani, H. Welcome to the tidyverse. Journal of 296! Open Source Software 2019, 4 (43), 1686. https://doi.org/10.21105/joss.01686. 297! https://github.com/paul-buerkner/brms. 299! https://mc-stan.org/cmdstanr/. 301! https://docs.ropensci.org/assertr/. 303!
(10) Müller, K. here: A simpler way to find your files. https://here.r-lib.org/. 304!
(11) Pedersen, T. L. patchwork: The composer of plots. https://patchwork.data-305! imaginist.com. 306!
(12) Lawlor, J. PNWColors: Color palettes inspired by nature in the US pacific 307! northwest. https://github.com/jakelawlor/PNWColors. 308!
(13) Gelman, A.; Carlin, J. B.; Stern, H. S.; Dunson, B., David; Vehtari, A.; Rubin, D. 309! B. Bayesian Data Analysis, Third edition.; Chapman & Hall/CRC texts in statistical 310! science; CRC Press: Boca Raton, 2014. 311!
(14) McElreath, R. Statistical Rethinking: A Bayesian Course with Examples in R and 312! Stan; Chapman & Hall/CRC texts in statistical science series; CRC Press/Taylor & 313! Francis Group: Boca Raton, 2016. 314!
(15) Stan Development Team. Stan modeling language users guide and reference 315! manual, version 2.34. http://mc-stan.org/. 316!
(16) Simpson, G. L. Modelling Palaeoecological Time Series Using Generalised 317! Additive Models. Frontiers in Ecology and Evolution 2018, 6, 149. 318! https://doi.org/10.3389/fevo.2018.00149. 319!
(17) Murphy, R. R.; Perry, E.; Harcum, J.; Keisman, J. A Generalized Additive Model 320! Approach to Evaluating Water Quality: Chesapeake Bay Case Study. Environmental 321! Modelling & Software 2019, 118, 1–13. https://doi.org/10.1016/j.envsoft.2019.03.027. 322!
(18) Beck, M. W.; De Valpine, P.; Murphy, R.; Wren, I.; Chelsky, A.; Foley, M.; Senn, 323! D. B. Multi-Scale Trend Analysis of Water Quality Using Error Propagation of 324! Generalized Additive Models. Science of The Total Environment 2022, 802, 149927. 325! https://doi.org/10.1016/j.scitotenv.2021.149927. 326!
(19) Chen, T. Y.-J.; Guikema, S. D. Prediction of Water Main Failures with the Spatial 327! Clustering of Breaks. Reliability Engineering & System Safety 2020, 203, 107108. 328! https://doi.org/10.1016/j.ress.2020.107108. 329!
(20) Trueman, B. F.; James, W.; Shu, T.; Doré, E.; Gagnon, G. A. Comparing 330! Corrosion Control Treatments for Drinking Water Using a Robust Bayesian Generalized 331! Additive Model. ACS ES&T Engineering 2022, acsestengg.2c00194. 332! https://doi.org/10.1021/acsestengg.2c00194. 333!
(21) Wood, S. N. Generalized Additive Models: An Introduction with R, 2nd ed.; 334! Chapman; Hall/CRC, 2017. 335!
(22) Abokifa, A. A.; Sela, L. Integrating Spatial Clustering with Predictive Modeling of 336! Pipe Failures in Water Distribution Systems. Urban Water Journal 2023, 20 (4), 465–337! 476. https://doi.org/10.1080/1573062X.2023.2180393. 338!
(23) Hopke, P. K.; Liu, C.; Rubin, D. B. Multiple Imputation for Multivariate Data with 339! Missing and Below‐Threshold Measurements: Time‐Series Concentrations of Pollutants 340! in the Arctic. Biometrics 2001, 57 (1), 22–33. https://doi.org/10.1111/j.0006-341! 341X.2001.00022.x. 342!
(24) Helsel, D. R.; Hirsch, R. M.; Ryberg, K. R.; Archfield, S. A.; Gilroy, E. J. Statistical 343! Methods in Water Resources; U.S. Department of the Interior; U.S. Geological Survey, 344! 2020; Vol. Techniques and Methods 4–A3. 345!
(25) Hastie, T.; Tibshirani, R.; Friedman, J. The Elements of Statistical Learning; 346! Springer Series in Statistics; Springer New York: New York, NY, 2009. 347! https://doi.org/10.1007/978-0-387-84858-7. 348!
(26) Bishop, C. M. Pattern Recognition and Machine Learning; Information science 349! and statistics; Springer: New York, 2006. 350!
(27) Kucukelbir, A.; Tran, D.; Ranganath, R.; Gelman, A.; Blei, D. M. Automatic 351! Differentiation Variational Inference. Journal of Machine Learning Research 2017, 18 352! (14), 1–45. 353!